# Quick Start Guide - SANGO DR Detection System

## ğŸš€ HÆ°á»›ng dáº«n nhanh

### BÆ°á»›c 1: Kiá»ƒm tra há»‡ thá»‘ng

```bash
python test_system.py
```

âœ… Äáº£m báº£o Ã­t nháº¥t 5/7 tests pass (CUDA test cÃ³ thá»ƒ fail náº¿u khÃ´ng cÃ³ GPU)

### BÆ°á»›c 2: PhÃ¢n tÃ­ch dá»¯ liá»‡u (TÃ¹y chá»n)

```bash
python utils.py
```

Script nÃ y sáº½:
- PhÃ¢n tÃ­ch phÃ¢n bá»‘ classes
- Kiá»ƒm tra kÃ­ch thÆ°á»›c áº£nh
- Æ¯á»›c tÃ­nh thá»i gian training
- Táº¡o visualization cá»§a dá»¯ liá»‡u

### BÆ°á»›c 3: Training

#### Option A: Train Classification Only (Nhanh hÆ¡n)
```bash
python main.py --mode train_classification --epochs 30 --batch_size 4
```

#### Option B: Train Segmentation Only
```bash
python main.py --mode train_segmentation --epochs 30 --batch_size 4
```

#### Option C: Train Both (Recommended)
```bash
python main.py --mode train_all --epochs 30 --batch_size 4
```

### BÆ°á»›c 4: ÄÃ¡nh giÃ¡ model

```bash
python evaluate.py
```

### BÆ°á»›c 5: Inference trÃªn áº£nh má»›i

```bash
python main.py --mode inference --image_path "data/B. Disease Grading/1. Original Images/a. Training Set/IDRiD_001.jpg"
```

## ğŸ“Š Tham sá»‘ cÃ³ thá»ƒ Ä‘iá»u chá»‰nh

### Náº¿u gáº·p Out of Memory:

**Trong file `config.py`:**
```python
IMG_SIZE = 224          # Giáº£m tá»« 256
BATCH_SIZE = 2          # Giáº£m tá»« 4
GRU_HIDDEN_SIZE = 64    # Giáº£m tá»« 128
```

**Trong `train_segmentation.py`:**
```python
model = create_segmentation_model(base_filters=16)  # Giáº£m tá»« 32
```

### Äá»ƒ training nhanh hÆ¡n (nhÆ°ng accuracy tháº¥p hÆ¡n):

```python
NUM_EPOCHS = 20         # Giáº£m tá»« 50
POPULATION_SIZE = 10    # Giáº£m tá»« 20 (SANGO)
MAX_ITERATIONS = 15     # Giáº£m tá»« 30 (SANGO)
```

## ğŸ¯ Expected Results

### Classification:
- **Accuracy**: 85-95% (tÃ¹y theo dá»¯ liá»‡u)
- **F1 Score**: 0.82-0.92
- **Training Time**: ~2-4 hours (GPU), ~20-30 hours (CPU)

### Segmentation:
- **IoU**: 0.65-0.80
- **Dice Score**: 0.70-0.85
- **Training Time**: ~3-5 hours (GPU), ~30-40 hours (CPU)

## ğŸ“ Output Structure

```
outputs/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.pth              # Best classification model
â”‚   â”œâ”€â”€ best_seg_model.pth          # Best segmentation model
â”‚   â””â”€â”€ checkpoint_epoch_*.pth      # Training checkpoints
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ tensorboard logs
â””â”€â”€ results/
    â”œâ”€â”€ classification_metrics.png
    â”œâ”€â”€ segmentation_metrics.png
    â”œâ”€â”€ confusion_matrix_classification.png
    â”œâ”€â”€ segmentation_evaluation.png
    â””â”€â”€ inference_*.jpg
```

## ğŸ”§ Troubleshooting

### 1. ImportError hoáº·c ModuleNotFoundError
```bash
pip install -r requirements.txt
```

### 2. CUDA Out of Memory
- Giáº£m `BATCH_SIZE` trong config.py
- Giáº£m `IMG_SIZE` xuá»‘ng 224 hoáº·c 192
- Táº¯t má»™t sá»‘ augmentation

### 3. Training quÃ¡ cháº­m
- Sá»­ dá»¥ng GPU (CUDA)
- Giáº£m sá»‘ epochs
- Giáº£m POPULATION_SIZE cá»§a SANGO
- Set `apply_gabor=False` trong preprocessing

### 4. Accuracy tháº¥p
- TÄƒng sá»‘ epochs
- Báº­t data augmentation
- Sá»­ dá»¥ng pretrained weights (Ä‘Ã£ báº­t máº·c Ä‘á»‹nh)
- TÄƒng learning rate hoáº·c dÃ¹ng learning rate scheduler

## ğŸ’¡ Tips Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t

1. **Data Augmentation**: ÄÃ£ báº­t máº·c Ä‘á»‹nh, giÃºp trÃ¡nh overfitting
2. **Mixed Precision Training**: ÄÃ£ báº­t (AMP), giáº£m 50% memory usage
3. **Gradient Accumulation**: Hiá»‡u á»©ng batch size lá»›n hÆ¡n
4. **Early Stopping**: Tá»± Ä‘á»™ng dá»«ng khi khÃ´ng improve (patience=10)
5. **Learning Rate Scheduling**: ReduceLROnPlateau cho classification

## ğŸ“ CÃ¡c lá»‡nh hay dÃ¹ng

```bash
# Kiá»ƒm tra GPU
python -c "import torch; print(torch.cuda.is_available())"

# Test má»™t sample nhanh
python inference.py

# Xem tensorboard logs
tensorboard --logdir outputs/logs

# ÄÃ¡nh giÃ¡ model
python evaluate.py

# PhÃ¢n tÃ­ch dá»¯ liá»‡u
python utils.py
```

## ğŸ“ Hiá»ƒu vá» SANGO

SANGO (Self-Adaptive Northern Goshawk Optimization) Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ:
- Tá»± Ä‘á»™ng tÃ¬m hyperparameters tá»‘i Æ°u cho GRU
- CÃ¢n báº±ng giá»¯a exploration (tÃ¬m kiáº¿m global) vÃ  exploitation (tá»‘i Æ°u local)
- Sá»­ dá»¥ng Levy flight cho random walk hiá»‡u quáº£

**Khi nÃ o SANGO hoáº¡t Ä‘á»™ng?**
- Trong quÃ¡ trÃ¬nh training classification model
- Tá»± Ä‘á»™ng optimize hidden_size, dropout_rate, learning_rate

## ğŸ“Š Metrics Explained

### Classification:
- **Accuracy**: % dá»± Ä‘oÃ¡n Ä‘Ãºng
- **F1 Score**: Harmonic mean cá»§a precision vÃ  recall
- **Precision**: Trong nhá»¯ng dá»± Ä‘oÃ¡n positive, bao nhiÃªu % Ä‘Ãºng
- **Recall**: Trong nhá»¯ng case thá»±c sá»± positive, model detect Ä‘Æ°á»£c bao nhiÃªu %

### Segmentation:
- **IoU**: Intersection over Union - Ä‘á»™ overlap giá»¯a prediction vÃ  ground truth
- **Dice Score**: TÆ°Æ¡ng tá»± IoU, nhÆ°ng Ä‘Ã¡nh trá»ng intersection cao hÆ¡n
- **Pixel Accuracy**: % pixels Ä‘Æ°á»£c phÃ¢n loáº¡i Ä‘Ãºng

## ğŸ”¬ Advanced: Custom Training

Náº¿u muá»‘n customize training loop:

```python
from train_classification import ClassificationTrainer
from classification_model import create_classification_model
import config

# Create model
model = create_classification_model(num_classes=5)

# Create trainer vá»›i custom parameters
trainer = ClassificationTrainer(model, device, use_amp=True)

# Custom learning rate
trainer.optimizer = torch.optim.AdamW(
    model.parameters(), 
    lr=1e-3,  # Higher learning rate
    weight_decay=1e-4
)

# Train
trainer.train(train_loader, val_loader, num_epochs=50)
```

## ğŸ“š References

Paper: Sharma, N., & Lalwani, P. (2025). A multi model deep net with an explainable AI based framework for diabetic retinopathy segmentation and classification. Scientific Reports, 15, 8777.

## ğŸ†˜ Need Help?

1. Check `README.md` for detailed documentation
2. Run `python test_system.py` to diagnose issues
3. Check error logs in terminal
4. Reduce batch size if OOM errors occur

---

**Happy Training! ğŸ‰**

