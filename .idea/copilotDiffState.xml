<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/dataset.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/dataset.py" />
              <option name="originalContent" value="&quot;&quot;&quot;&#10;Dataset and DataLoader for DR Classification and Segmentation&#10;&quot;&quot;&quot;&#10;&#10;import os&#10;import cv2&#10;import numpy as np&#10;import pandas as pd&#10;import torch&#10;from torch.utils.data import Dataset, DataLoader&#10;import albumentations as A&#10;from albumentations.pytorch import ToTensorV2&#10;from typing import Tuple, Optional&#10;import config&#10;&#10;&#10;class DRClassificationDataset(Dataset):&#10;    &quot;&quot;&quot;Dataset for DR classification&quot;&quot;&quot;&#10;&#10;    def __init__(self, image_dir: str, labels_csv: str, transform=None, is_train: bool = True):&#10;        self.image_dir = image_dir&#10;        self.transform = transform&#10;        self.is_train = is_train&#10;&#10;        # Read labels&#10;        df = pd.read_csv(labels_csv)&#10;        self.image_names = df['Image name'].values&#10;        self.labels = df['Retinopathy grade'].values&#10;&#10;    def __len__(self) -&gt; int:&#10;        return len(self.image_names)&#10;&#10;    def __getitem__(self, idx: int) -&gt; Tuple[torch.Tensor, int]:&#10;        # Load image&#10;        img_name = self.image_names[idx]&#10;        img_path = os.path.join(self.image_dir, f&quot;{img_name}.jpg&quot;)&#10;&#10;        image = cv2.imread(img_path)&#10;        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)&#10;&#10;        # Apply transforms&#10;        if self.transform:&#10;            augmented = self.transform(image=image)&#10;            image = augmented['image']&#10;&#10;        # Get label&#10;        label = int(self.labels[idx])&#10;&#10;        return image, label&#10;&#10;&#10;class DRSegmentationDataset(Dataset):&#10;    &quot;&quot;&quot;Dataset for DR lesion segmentation&quot;&quot;&quot;&#10;&#10;    def __init__(self, image_dir: str, mask_dir: str, transform=None,&#10;                 lesion_types: list = None):&#10;        self.image_dir = image_dir&#10;        self.mask_dir = mask_dir&#10;        self.transform = transform&#10;&#10;        # Define lesion types with folder names and file suffixes&#10;        if lesion_types is None:&#10;            self.lesion_types = [&#10;                ('1. Microaneurysms_', 'MA'),&#10;                ('2. Haemorrhages_', 'HE'),&#10;                ('3. Hard Exudates_', 'EX')&#10;            ]&#10;        else:&#10;            self.lesion_types = lesion_types&#10;&#10;        # Get all image files&#10;        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])&#10;&#10;    def __len__(self) -&gt; int:&#10;        return len(self.image_files)&#10;&#10;    def __getitem__(self, idx: int) -&gt; Tuple[torch.Tensor, torch.Tensor]:&#10;        # Load image&#10;        img_name = self.image_files[idx]&#10;        img_path = os.path.join(self.image_dir, img_name)&#10;        image = cv2.imread(img_path)&#10;        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)&#10;&#10;        # Load masks for all lesion types&#10;        base_name = img_name.replace('.jpg', '')&#10;        masks = []&#10;&#10;        for folder_name, suffix in self.lesion_types:&#10;            mask_path = os.path.join(self.mask_dir, folder_name, f&quot;{base_name}_{suffix}.tif&quot;)&#10;&#10;            if os.path.exists(mask_path):&#10;                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)&#10;            else:&#10;                # Create empty mask if not exists&#10;                mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)&#10;&#10;            masks.append(mask)&#10;&#10;        # Stack masks (channels: MA, HEM, EX)&#10;        mask = np.stack(masks, axis=-1)&#10;&#10;        # Apply transforms&#10;        if self.transform:&#10;            augmented = self.transform(image=image, mask=mask)&#10;            image = augmented['image']&#10;            mask = augmented['mask']&#10;            &#10;            # Normalize mask to [0, 1]&#10;            mask = mask.float() / 255.0&#10;            &#10;            # Permute mask from [H, W, C] to [C, H, W] to match PyTorch convention&#10;            mask = mask.permute(2, 0, 1)&#10;        else:&#10;            # No transform: convert to tensor manually&#10;            mask = torch.from_numpy(mask).float() / 255.0&#10;            mask = mask.permute(2, 0, 1)&#10;            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0&#10;&#10;        return image, mask&#10;&#10;&#10;def get_classification_transforms(is_train: bool = True, img_size: int = 256):&#10;    &quot;&quot;&quot;Get augmentation transforms for classification&quot;&quot;&quot;&#10;&#10;    if is_train:&#10;        transform = A.Compose([&#10;            A.Resize(img_size, img_size),&#10;            A.HorizontalFlip(p=0.5),&#10;            A.VerticalFlip(p=0.5),&#10;            A.Rotate(limit=15, p=0.5),&#10;            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),&#10;            A.GaussNoise(p=0.3),&#10;            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),&#10;            ToTensorV2()&#10;        ])&#10;    else:&#10;        transform = A.Compose([&#10;            A.Resize(img_size, img_size),&#10;            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),&#10;            ToTensorV2()&#10;        ])&#10;&#10;    return transform&#10;&#10;&#10;def get_segmentation_transforms(is_train: bool = True, img_size: int = 256):&#10;    &quot;&quot;&quot;Get augmentation transforms for segmentation&quot;&quot;&quot;&#10;&#10;    if is_train:&#10;        transform = A.Compose([&#10;            A.Resize(img_size, img_size),&#10;            A.HorizontalFlip(p=0.5),&#10;            A.VerticalFlip(p=0.5),&#10;            A.Rotate(limit=15, p=0.5),&#10;            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),&#10;            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),&#10;            ToTensorV2()&#10;        ])&#10;    else:&#10;        transform = A.Compose([&#10;            A.Resize(img_size, img_size),&#10;            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),&#10;            ToTensorV2()&#10;        ])&#10;&#10;    return transform&#10;&#10;&#10;def get_classification_loaders(batch_size: int = 4, num_workers: int = 2, img_size: int = 256):&#10;    &quot;&quot;&quot;Create data loaders for classification&quot;&quot;&quot;&#10;&#10;    train_dataset = DRClassificationDataset(&#10;        image_dir=config.CLASS_TRAIN_IMG_DIR,&#10;        labels_csv=config.CLASS_TRAIN_LABELS,&#10;        transform=get_classification_transforms(is_train=True, img_size=img_size),&#10;        is_train=True&#10;    )&#10;&#10;    # Check if test labels exist&#10;    if os.path.exists(config.CLASS_TEST_LABELS):&#10;        test_dataset = DRClassificationDataset(&#10;            image_dir=config.CLASS_TEST_IMG_DIR,&#10;            labels_csv=config.CLASS_TEST_LABELS,&#10;            transform=get_classification_transforms(is_train=False, img_size=img_size),&#10;            is_train=False&#10;        )&#10;    else:&#10;        # Use validation split from training data&#10;        from sklearn.model_selection import train_test_split&#10;        train_indices, val_indices = train_test_split(&#10;            range(len(train_dataset)), test_size=0.2, random_state=config.SEED&#10;        )&#10;&#10;        train_dataset_split = torch.utils.data.Subset(train_dataset, train_indices)&#10;        test_dataset = torch.utils.data.Subset(train_dataset, val_indices)&#10;        train_dataset = train_dataset_split&#10;&#10;    train_loader = DataLoader(&#10;        train_dataset,&#10;        batch_size=batch_size,&#10;        shuffle=True,&#10;        num_workers=num_workers,&#10;        pin_memory=True&#10;    )&#10;&#10;    test_loader = DataLoader(&#10;        test_dataset,&#10;        batch_size=batch_size,&#10;        shuffle=False,&#10;        num_workers=num_workers,&#10;        pin_memory=True&#10;    )&#10;&#10;    return train_loader, test_loader&#10;&#10;&#10;def get_segmentation_loaders(batch_size: int = 4, num_workers: int = 2, img_size: int = 256):&#10;    &quot;&quot;&quot;Create data loaders for segmentation&quot;&quot;&quot;&#10;&#10;    train_dataset = DRSegmentationDataset(&#10;        image_dir=config.SEG_TRAIN_IMG_DIR,&#10;        mask_dir=config.SEG_TRAIN_MASK_DIR,&#10;        transform=get_segmentation_transforms(is_train=True, img_size=img_size)&#10;    )&#10;&#10;    # Use validation split&#10;    from sklearn.model_selection import train_test_split&#10;    train_indices, val_indices = train_test_split(&#10;        range(len(train_dataset)), test_size=0.2, random_state=config.SEED&#10;    )&#10;&#10;    train_dataset_split = torch.utils.data.Subset(train_dataset, train_indices)&#10;    val_dataset = torch.utils.data.Subset(train_dataset, val_indices)&#10;&#10;    train_loader = DataLoader(&#10;        train_dataset_split,&#10;        batch_size=batch_size,&#10;        shuffle=True,&#10;        num_workers=num_workers,&#10;        pin_memory=True&#10;    )&#10;&#10;    val_loader = DataLoader(&#10;        val_dataset,&#10;        batch_size=batch_size,&#10;        shuffle=False,&#10;        num_workers=num_workers,&#10;        pin_memory=True&#10;    )&#10;&#10;    return train_loader, val_loader&#10;" />
              <option name="updatedContent" value="&quot;&quot;&quot;&#10;Dataset and DataLoader for DR Classification and Segmentation&#10;&quot;&quot;&quot;&#10;&#10;import os&#10;import cv2&#10;import numpy as np&#10;import pandas as pd&#10;import torch&#10;from torch.utils.data import Dataset, DataLoader&#10;import albumentations as A&#10;from albumentations.pytorch import ToTensorV2&#10;from typing import Tuple, Optional&#10;import config&#10;&#10;&#10;class DRClassificationDataset(Dataset):&#10;    &quot;&quot;&quot;Dataset for DR classification&quot;&quot;&quot;&#10;&#10;    def __init__(self, image_dir: str, labels_csv: str, transform=None, is_train: bool = True):&#10;        self.image_dir = image_dir&#10;        self.transform = transform&#10;        self.is_train = is_train&#10;&#10;        # Read labels&#10;        df = pd.read_csv(labels_csv)&#10;        self.image_names = df['Image name'].values&#10;        self.labels = df['Retinopathy grade'].values&#10;&#10;    def __len__(self) -&gt; int:&#10;        return len(self.image_names)&#10;&#10;    def __getitem__(self, idx: int) -&gt; Tuple[torch.Tensor, int]:&#10;        # Load image&#10;        img_name = self.image_names[idx]&#10;        img_path = os.path.join(self.image_dir, f&quot;{img_name}.jpg&quot;)&#10;&#10;        image = cv2.imread(img_path)&#10;        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)&#10;&#10;        # Apply transforms&#10;        if self.transform:&#10;            augmented = self.transform(image=image)&#10;            image = augmented['image']&#10;&#10;        # Get label&#10;        label = int(self.labels[idx])&#10;&#10;        return image, label&#10;&#10;&#10;class DRSegmentationDataset(Dataset):&#10;    &quot;&quot;&quot;Dataset for DR lesion segmentation&quot;&quot;&quot;&#10;&#10;    def __init__(self, image_dir: str, mask_dir: str, transform=None,&#10;                 lesion_types: list = None):&#10;        self.image_dir = image_dir&#10;        self.mask_dir = mask_dir&#10;        self.transform = transform&#10;&#10;        # Define lesion types with folder names and file suffixes&#10;        if lesion_types is None:&#10;            self.lesion_types = [&#10;                ('1. Microaneurysms_', 'MA'),&#10;                ('2. Haemorrhages_', 'HE'),&#10;                ('3. Hard Exudates_', 'EX')&#10;            ]&#10;        else:&#10;            self.lesion_types = lesion_types&#10;&#10;        # Get all image files&#10;        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')])&#10;&#10;    def __len__(self) -&gt; int:&#10;        return len(self.image_files)&#10;&#10;    def __getitem__(self, idx: int) -&gt; Tuple[torch.Tensor, torch.Tensor]:&#10;        # Load image&#10;        img_name = self.image_files[idx]&#10;        img_path = os.path.join(self.image_dir, img_name)&#10;        image = cv2.imread(img_path)&#10;        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)&#10;&#10;        # Load masks for all lesion types&#10;        base_name = img_name.replace('.jpg', '')&#10;        masks = []&#10;&#10;        for folder_name, suffix in self.lesion_types:&#10;            mask_path = os.path.join(self.mask_dir, folder_name, f&quot;{base_name}_{suffix}.tif&quot;)&#10;&#10;            if os.path.exists(mask_path):&#10;                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)&#10;            else:&#10;                # Create empty mask if not exists&#10;                mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)&#10;&#10;            masks.append(mask)&#10;&#10;        # Stack masks (channels: MA, HEM, EX)&#10;        mask = np.stack(masks, axis=-1)&#10;&#10;        # Apply transforms&#10;        if self.transform:&#10;            augmented = self.transform(image=image, mask=mask)&#10;            image = augmented['image']&#10;            mask = augmented['mask']&#10;            &#10;            # Normalize mask to [0, 1]&#10;            mask = mask.float() / 255.0&#10;            &#10;            # Permute mask from [H, W, C] to [C, H, W] to match PyTorch convention&#10;            mask = mask.permute(2, 0, 1)&#10;        else:&#10;            # No transform: convert to tensor manually&#10;            mask = torch.from_numpy(mask).float() / 255.0&#10;            mask = mask.permute(2, 0, 1)&#10;            image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0&#10;&#10;        return image, mask&#10;&#10;&#10;def get_classification_transforms(is_train: bool = True, img_size: int = 256):&#10;    &quot;&quot;&quot;Get augmentation transforms for classification&quot;&quot;&quot;&#10;&#10;    if is_train:&#10;        transform = A.Compose([&#10;            A.Resize(img_size, img_size),&#10;            A.HorizontalFlip(p=0.5),&#10;            A.VerticalFlip(p=0.5),&#10;            A.Rotate(limit=15, p=0.5),&#10;            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),&#10;            A.GaussNoise(p=0.3),&#10;            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),&#10;            ToTensorV2()&#10;        ])&#10;    else:&#10;        transform = A.Compose([&#10;            A.Resize(img_size, img_size),&#10;            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),&#10;            ToTensorV2()&#10;        ])&#10;&#10;    return transform&#10;&#10;&#10;def get_segmentation_transforms(is_train: bool = True, img_size: int = 256):&#10;    &quot;&quot;&quot;Get augmentation transforms for segmentation&quot;&quot;&quot;&#10;&#10;    if is_train:&#10;        transform = A.Compose([&#10;            A.Resize(img_size, img_size),&#10;            A.HorizontalFlip(p=0.5),&#10;            A.VerticalFlip(p=0.5),&#10;            A.Rotate(limit=15, p=0.5),&#10;            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),&#10;            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),&#10;            ToTensorV2()&#10;        ])&#10;    else:&#10;        transform = A.Compose([&#10;            A.Resize(img_size, img_size),&#10;            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),&#10;            ToTensorV2()&#10;        ])&#10;&#10;    return transform&#10;&#10;&#10;def get_classification_loaders(batch_size: int = 4, num_workers: int = 2, img_size: int = 256):&#10;    &quot;&quot;&quot;Create data loaders for classification&quot;&quot;&quot;&#10;&#10;    train_dataset = DRClassificationDataset(&#10;        image_dir=config.CLASS_TRAIN_IMG_DIR,&#10;        labels_csv=config.CLASS_TRAIN_LABELS,&#10;        transform=get_classification_transforms(is_train=True, img_size=img_size),&#10;        is_train=True&#10;    )&#10;&#10;    # Check if test labels exist&#10;    if os.path.exists(config.CLASS_TEST_LABELS):&#10;        test_dataset = DRClassificationDataset(&#10;            image_dir=config.CLASS_TEST_IMG_DIR,&#10;            labels_csv=config.CLASS_TEST_LABELS,&#10;            transform=get_classification_transforms(is_train=False, img_size=img_size),&#10;            is_train=False&#10;        )&#10;    else:&#10;        # Use validation split from training data&#10;        from sklearn.model_selection import train_test_split&#10;        train_indices, val_indices = train_test_split(&#10;            range(len(train_dataset)), test_size=0.2, random_state=config.SEED&#10;        )&#10;&#10;        train_dataset_split = torch.utils.data.Subset(train_dataset, train_indices)&#10;        test_dataset = torch.utils.data.Subset(train_dataset, val_indices)&#10;        train_dataset = train_dataset_split&#10;&#10;    train_loader = DataLoader(&#10;        train_dataset,&#10;        batch_size=batch_size,&#10;        shuffle=True,&#10;        num_workers=num_workers,&#10;        pin_memory=True&#10;    )&#10;&#10;    test_loader = DataLoader(&#10;        test_dataset,&#10;        batch_size=batch_size,&#10;        shuffle=False,&#10;        num_workers=num_workers,&#10;        pin_memory=True&#10;    )&#10;&#10;    return train_loader, test_loader&#10;&#10;&#10;def get_segmentation_loaders(batch_size: int = 4, num_workers: int = 2, img_size: int = 256):&#10;    &quot;&quot;&quot;Create data loaders for segmentation&quot;&quot;&quot;&#10;&#10;    train_dataset = DRSegmentationDataset(&#10;        image_dir=config.SEG_TRAIN_IMG_DIR,&#10;        mask_dir=config.SEG_TRAIN_MASK_DIR,&#10;        transform=get_segmentation_transforms(is_train=True, img_size=img_size)&#10;    )&#10;&#10;    # Use validation split&#10;    from sklearn.model_selection import train_test_split&#10;    train_indices, val_indices = train_test_split(&#10;        range(len(train_dataset)), test_size=0.2, random_state=config.SEED&#10;    )&#10;&#10;    train_dataset_split = torch.utils.data.Subset(train_dataset, train_indices)&#10;    val_dataset = torch.utils.data.Subset(train_dataset, val_indices)&#10;&#10;    train_loader = DataLoader(&#10;        train_dataset_split,&#10;        batch_size=batch_size,&#10;        shuffle=True,&#10;        num_workers=num_workers,&#10;        pin_memory=True&#10;    )&#10;&#10;    val_loader = DataLoader(&#10;        val_dataset,&#10;        batch_size=batch_size,&#10;        shuffle=False,&#10;        num_workers=num_workers,&#10;        pin_memory=True&#10;    )&#10;&#10;    return train_loader, val_loader" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>